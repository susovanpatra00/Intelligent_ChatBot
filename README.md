# ğŸ“š Intelligence Assistant (DO33 Bot)

An intelligent assistant that allows users to query PDF and Excel documents using natural language. Built using **React + Vite + TypeScript** on the frontend and **Flask + LangChain + OpenAI** on the backend. The system supports contextual retrieval, optional reasoning, and web search.

---

## ğŸš€ Features

- âœ… Natural language queries on PDFs and Excel files
- ğŸ” Internal document retrieval using vector search (FAISS)
- ğŸ§  Optional LLM-based reasoning
- ğŸŒ Optional real-time web search via OpenAI
- ğŸ“ Source file traceability and download support
- ğŸ§¾ Feedback system for likes/dislikes with logging
- ğŸ™ï¸ Voice-to-text input (speech recognition)
- ğŸ“ Modular ingestion: Add new file types easily

---

## ğŸ“ Folder Structure

```

DO33\_Final/
â”œâ”€â”€ backend/                     # All backend code
â”‚   â”œâ”€â”€ app.py                   # Flask API server
â”‚   â”œâ”€â”€ config.py                # Global config and flags
â”‚   â”œâ”€â”€ ingestion/               # Data ingestion logic
â”‚   â”‚   â”œâ”€â”€ ingest\_pdf.py
â”‚   â”‚   â”œâ”€â”€ ingest\_excel.py
â”‚   â”œâ”€â”€ vectorstore/             # Stored FAISS indexes
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ reasoning/
â”‚   â”œâ”€â”€ websearch/
â”‚   â”œâ”€â”€ llm\_response/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ data/                    # Embedded document metadata (pkl, json)
â”œâ”€â”€ Data/                        # Raw files
â”‚   â”œâ”€â”€ PDF/
â”‚   â””â”€â”€ EXCEL/
â”œâ”€â”€ frontend/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.ts
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt


````

---

## âš™ï¸ Setup Instructions

### 1. ğŸ§  Backend Setup

#### a. Create a Python virtual environment

```bash
python -m venv do33_env
source do33_env/bin/activate  # or do33_env\Scripts\activate on Windows
````

#### b. Install dependencies

```bash
pip install -r requirements.txt
```

#### c. Add OpenAI API Key

Create a `.env` file in the backend root:

```env
OPENAI_API_KEY=your_openai_api_key
```

#### d. Run ingestion scripts

```bash
python data_ingestion/generate_embeddings.py
```

#### e. Start the Flask server

```bash
python backend\app.py
```

Server will run at: `http://localhost:5001`

---

### 2. ğŸ’» Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend will run at: `http://localhost:8080`

---

## ğŸ§ª Example Usage

* Ask: *"What is the problem with the XYZ component and how was it solved?"*
* Enable reasoning or web search (optional)
* Receive a structured answer with source file buttons
* Click source buttons to open documents
* Leave feedback via ğŸ‘ / ğŸ‘

---

## ğŸ›  Config Options

Inside `backend/config.py`:

```python
ENABLE_PDF = True
ENABLE_EXCEL = True
```

---

## ğŸ“¦ Dependencies

* **Frontend**: React, Vite, TypeScript, Tailwind CSS, Shadcn-UI
* **Backend**: Flask, OpenAI, LangChain, FAISS, Pandas
* **Embeddings**: BAAI/bge-base-en-v1.5 via HuggingFace
* **LLM**: GPT-4o or GPT-3.5-turbo (OpenAI)

---

## ğŸ§  Future Improvements

* Role-based access and authentication
* Add support for CSV/Docx ingestion
* Summary and analytics dashboard
* Row-level preview for Excel rows used in answers
